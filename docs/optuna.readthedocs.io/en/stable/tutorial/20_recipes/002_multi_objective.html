<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Multi-objective Optimization with Optuna &mdash; Optuna 4.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=d0d4e556" />

  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=17614d54"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=a56c686a"></script>
        
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

<!-- RTD Extra Head -->



<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": true, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/docs/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": null, "language": "en", "page": "tutorial/20_recipes/002_multi_objective", "programming_language": "words", "project": "optuna", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_rtd_theme", "user_analytics_code": "", "version": "stable"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>



<!-- end RTD <extrahead> -->
<script async type="text/javascript" src="/_/static/javascript/readthedocs-addons.js"></script><meta name="readthedocs-project-slug" content="optuna" /><meta name="readthedocs-version-slug" content="stable" /><meta name="readthedocs-resolver-filename" content="/tutorial/20_recipes/002_multi_objective.html" /><meta name="readthedocs-http-status" content="200" /></head>

<body class="wy-body-for-nav">
    <div class="navbar">
        <div class="navbar ml-auto">
            <ul class="navbar-nav">
                <li>
                    <a href="https://optuna.org/#key_features" class="header_link">Key Features</a>
                </li>
                <li>
                    <a href="https://optuna.org/#code_examples" class="header_link">Code Examples</a>
                </li>
                <li>
                    <a href="https://optuna.org/#installation" class="header_link">Installation</a>
                </li>
                <li>
                    <a href="https://optuna.org/#dashboard" class="header_link">Dashboard</a>
                </li>
                <li>
                    <a href="https://optuna.org/#hub" class="header_link">OptunaHub</a>
                </li>
                <li>
                    <a href="https://optuna.org/#blog" class="header_link">Blog</a>
                </li>
                <li>
                    <a href="https://optuna.org/#video" class="header_link">Videos</a>
                </li>
                <li>
                    <a href="https://optuna.org/#paper" class="header_link">Paper</a>
                </li>
            </ul>
        </div>
    </div>
     

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/optuna-logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                stable
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Optuna</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <!-- This file is necessary to remove "Edit on Github" button from readthedocs by following https://docs.readthedocs.io/en/stable/guides/remove-edit-buttons.html#remove-links-from-top-right-corner --><div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Multi-objective Optimization with Optuna</li>

  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-tutorial-20-recipes-002-multi-objective-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="multi-objective-optimization-with-optuna">
<span id="multi-objective"></span><span id="sphx-glr-tutorial-20-recipes-002-multi-objective-py"></span><h1>Multi-objective Optimization with Optuna<a class="headerlink" href="#multi-objective-optimization-with-optuna" title="Link to this heading"></a></h1>
<p>This tutorial showcases Optuna’s multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.</p>
<p>We use <a class="reference external" href="https://github.com/facebookresearch/fvcore">fvcore</a> to measure FLOPS.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">fvcore.nn</span> <span class="kn">import</span> <span class="n">FlopCountAnalysis</span>

<span class="kn">import</span> <span class="nn">optuna</span>


<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">if</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DIR</span></a> <span class="o">=</span> <span class="s2">&quot;..&quot;</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BATCHSIZE</span></a> <span class="o">=</span> <span class="mi">128</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N_TRAIN_EXAMPLES</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BATCHSIZE</span></a> <span class="o">*</span> <span class="mi">30</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N_VALID_EXAMPLES</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BATCHSIZE</span></a> <span class="o">*</span> <span class="mi">10</span>


<span class="k">def</span> <span class="nf">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;n_layers&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">in_features</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;n_units_l</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">())</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;dropout_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="n">p</span><span class="p">))</span>

        <span class="n">in_features</span> <span class="o">=</span> <span class="n">out_features</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" title="torch.nn.LogSoftmax" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span></a><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>


<span class="c1"># Defines training and evaluation.</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss" title="torch.nn.functional.nll_loss" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span></a><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <a href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N_VALID_EXAMPLES</span></a>

    <span class="n">flops</span> <span class="o">=</span> <span class="n">FlopCountAnalysis</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a><span class="p">),))</span><span class="o">.</span><span class="n">total</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<p>Define multi-objective objective function.
Objectives are FLOPS and accuracy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span></a><span class="p">(</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span>
        <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span></a><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N_TRAIN_EXAMPLES</span></a><span class="p">))),</span>
        <span class="n">batch_size</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BATCHSIZE</span></a><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">val_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span></a><span class="p">(</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span>
        <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span></a><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N_VALID_EXAMPLES</span></a><span class="p">))),</span>
        <span class="n">batch_size</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BATCHSIZE</span></a><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEVICE</span></a><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
    <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<section id="run-multi-objective-optimization">
<h2>Run multi-objective optimization<a class="headerlink" href="#run-multi-objective-optimization" title="Link to this heading"></a></h2>
<p>If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set <code class="docutils literal notranslate"><span class="pre">directions</span></code> to <code class="docutils literal notranslate"><span class="pre">[&quot;minimize&quot;,</span> <span class="pre">&quot;maximize&quot;]</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">directions</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">,</span> <span class="s2">&quot;maximize&quot;</span><span class="p">])</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of finished trials: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">trials</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Number of finished trials:  30
</pre></div>
</div>
<p>Check trials on Pareto front visually.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span><span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FLOPS&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.0.min.js"></script>                <div id="221294e8-8e3e-4b63-acff-e0f1638680d9" class="plotly-graph-div" style="height:100%; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("221294e8-8e3e-4b63-acff-e0f1638680d9")) {                    Plotly.newPlot(                        "221294e8-8e3e-4b63-acff-e0f1638680d9",                        [{"hovertemplate":"%{text}\u003cextra\u003eTrial\u003c\u002fextra\u003e","marker":{"color":[0,2,3,4,5,6,7,8,10,11,12,13,15,16,17,18,19,20,21,22,24,25,26,27,28,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 0,\u003cbr\u003e  \"values\": [\u003cbr\u003e    37632.0,\u003cbr\u003e    0.2203125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 46,\u003cbr\u003e    \"dropout_0\": 0.41544665399457203,\u003cbr\u003e    \"n_units_l1\": 28,\u003cbr\u003e    \"dropout_1\": 0.39754784029297824,\u003cbr\u003e    \"lr\": 1.1559589508376612e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 2,\u003cbr\u003e  \"values\": [\u003cbr\u003e    48356.0,\u003cbr\u003e    0.81015625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 53,\u003cbr\u003e    \"dropout_0\": 0.44385787382294783,\u003cbr\u003e    \"n_units_l1\": 108,\u003cbr\u003e    \"dropout_1\": 0.34698930038695774,\u003cbr\u003e    \"lr\": 0.0065090731097254715\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 3,\u003cbr\u003e  \"values\": [\u003cbr\u003e    87893.0,\u003cbr\u003e    0.75234375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 107,\u003cbr\u003e    \"dropout_0\": 0.45106302075001,\u003cbr\u003e    \"n_units_l1\": 15,\u003cbr\u003e    \"dropout_1\": 0.37876793011180165,\u003cbr\u003e    \"n_units_l2\": 96,\u003cbr\u003e    \"dropout_2\": 0.29935853091370535,\u003cbr\u003e    \"lr\": 0.001772271834198732\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 4,\u003cbr\u003e  \"values\": [\u003cbr\u003e    63882.0,\u003cbr\u003e    0.22734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 78,\u003cbr\u003e    \"dropout_0\": 0.37355626693639704,\u003cbr\u003e    \"n_units_l1\": 17,\u003cbr\u003e    \"dropout_1\": 0.35915645320419853,\u003cbr\u003e    \"n_units_l2\": 52,\u003cbr\u003e    \"dropout_2\": 0.4754422154842257,\u003cbr\u003e    \"lr\": 5.525079530955051e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 5,\u003cbr\u003e  \"values\": [\u003cbr\u003e    69872.0,\u003cbr\u003e    0.834375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 88,\u003cbr\u003e    \"dropout_0\": 0.46631582663002935,\u003cbr\u003e    \"lr\": 0.003909234933108144\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 6,\u003cbr\u003e  \"values\": [\u003cbr\u003e    90644.0,\u003cbr\u003e    0.509375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 106,\u003cbr\u003e    \"dropout_0\": 0.36067949577559333,\u003cbr\u003e    \"n_units_l1\": 65,\u003cbr\u003e    \"dropout_1\": 0.2922481203568559,\u003cbr\u003e    \"lr\": 1.9515676595980457e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 7,\u003cbr\u003e  \"values\": [\u003cbr\u003e    75960.0,\u003cbr\u003e    0.79765625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 90,\u003cbr\u003e    \"dropout_0\": 0.42815492980784836,\u003cbr\u003e    \"n_units_l1\": 54,\u003cbr\u003e    \"dropout_1\": 0.49142515230041056,\u003cbr\u003e    \"lr\": 0.009634085175852156\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 8,\u003cbr\u003e  \"values\": [\u003cbr\u003e    24632.0,\u003cbr\u003e    0.60859375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 31,\u003cbr\u003e    \"dropout_0\": 0.32017323982946577,\u003cbr\u003e    \"n_units_l1\": 8,\u003cbr\u003e    \"dropout_1\": 0.4614288740110348,\u003cbr\u003e    \"lr\": 0.00038035349161440494\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 10,\u003cbr\u003e  \"values\": [\u003cbr\u003e    22750.0,\u003cbr\u003e    0.6109375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 28,\u003cbr\u003e    \"dropout_0\": 0.38905845232272085,\u003cbr\u003e    \"n_units_l1\": 21,\u003cbr\u003e    \"dropout_1\": 0.2592816593742929,\u003cbr\u003e    \"lr\": 0.05439602373371016\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 11,\u003cbr\u003e  \"values\": [\u003cbr\u003e    36627.0,\u003cbr\u003e    0.80234375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 43,\u003cbr\u003e    \"dropout_0\": 0.3187856805237749,\u003cbr\u003e    \"n_units_l1\": 55,\u003cbr\u003e    \"dropout_1\": 0.3048887520725502,\u003cbr\u003e    \"lr\": 0.003270821350327724\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 12,\u003cbr\u003e  \"values\": [\u003cbr\u003e    33267.0,\u003cbr\u003e    0.68984375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 39,\u003cbr\u003e    \"dropout_0\": 0.4701930518659196,\u003cbr\u003e    \"n_units_l1\": 29,\u003cbr\u003e    \"dropout_1\": 0.39229512459469573,\u003cbr\u003e    \"n_units_l2\": 40,\u003cbr\u003e    \"dropout_2\": 0.4616805805680994,\u003cbr\u003e    \"lr\": 0.012783875884816456\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 13,\u003cbr\u003e  \"values\": [\u003cbr\u003e    96868.0,\u003cbr\u003e    0.68125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 122,\u003cbr\u003e    \"dropout_0\": 0.3881655988827042,\u003cbr\u003e    \"lr\": 0.05539326463439923\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 15,\u003cbr\u003e  \"values\": [\u003cbr\u003e    76013.0,\u003cbr\u003e    0.81796875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 89,\u003cbr\u003e    \"dropout_0\": 0.38846983905565435,\u003cbr\u003e    \"n_units_l1\": 63,\u003cbr\u003e    \"dropout_1\": 0.3529607432937448,\u003cbr\u003e    \"lr\": 0.005344577199171819\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 16,\u003cbr\u003e  \"values\": [\u003cbr\u003e    69078.0,\u003cbr\u003e    0.82421875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 87,\u003cbr\u003e    \"dropout_0\": 0.24866015167453978,\u003cbr\u003e    \"lr\": 0.014116825767982134\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 17,\u003cbr\u003e  \"values\": [\u003cbr\u003e    71208.0,\u003cbr\u003e    0.346875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 73,\u003cbr\u003e    \"dropout_0\": 0.4328783333532621,\u003cbr\u003e    \"n_units_l1\": 76,\u003cbr\u003e    \"dropout_1\": 0.34630584430520717,\u003cbr\u003e    \"n_units_l2\": 98,\u003cbr\u003e    \"dropout_2\": 0.283300511806342,\u003cbr\u003e    \"lr\": 3.040665685503193e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 18,\u003cbr\u003e  \"values\": [\u003cbr\u003e    99100.0,\u003cbr\u003e    0.271875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 109,\u003cbr\u003e    \"dropout_0\": 0.21224696466892412,\u003cbr\u003e    \"n_units_l1\": 96,\u003cbr\u003e    \"dropout_1\": 0.3502220032604357,\u003cbr\u003e    \"n_units_l2\": 30,\u003cbr\u003e    \"dropout_2\": 0.27058915309344245,\u003cbr\u003e    \"lr\": 1.4327003012487746e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 19,\u003cbr\u003e  \"values\": [\u003cbr\u003e    21464.0,\u003cbr\u003e    0.390625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 26,\u003cbr\u003e    \"dropout_0\": 0.41328359559637107,\u003cbr\u003e    \"n_units_l1\": 30,\u003cbr\u003e    \"dropout_1\": 0.2982090844931407,\u003cbr\u003e    \"lr\": 0.0771192581634224\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 20,\u003cbr\u003e  \"values\": [\u003cbr\u003e    78379.0,\u003cbr\u003e    0.1953125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 86,\u003cbr\u003e    \"dropout_0\": 0.2754050362604854,\u003cbr\u003e    \"n_units_l1\": 75,\u003cbr\u003e    \"dropout_1\": 0.39378157734604863,\u003cbr\u003e    \"n_units_l2\": 53,\u003cbr\u003e    \"dropout_2\": 0.3474997607964425,\u003cbr\u003e    \"lr\": 0.07477205865727089\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 21,\u003cbr\u003e  \"values\": [\u003cbr\u003e    65108.0,\u003cbr\u003e    0.79140625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 82,\u003cbr\u003e    \"dropout_0\": 0.23924436930484794,\u003cbr\u003e    \"lr\": 0.00048084198167990314\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 22,\u003cbr\u003e  \"values\": [\u003cbr\u003e    44464.0,\u003cbr\u003e    0.64921875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 56,\u003cbr\u003e    \"dropout_0\": 0.2231544425732226,\u003cbr\u003e    \"lr\": 4.333622571836986e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 24,\u003cbr\u003e  \"values\": [\u003cbr\u003e    61778.0,\u003cbr\u003e    0.8109375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 72,\u003cbr\u003e    \"dropout_0\": 0.4792987538705976,\u003cbr\u003e    \"n_units_l1\": 65,\u003cbr\u003e    \"dropout_1\": 0.20463256950764064,\u003cbr\u003e    \"lr\": 0.00244218692559301\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 25,\u003cbr\u003e  \"values\": [\u003cbr\u003e    72254.0,\u003cbr\u003e    0.63046875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 91,\u003cbr\u003e    \"dropout_0\": 0.24834382714142475,\u003cbr\u003e    \"lr\": 3.5888166164060836e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 26,\u003cbr\u003e  \"values\": [\u003cbr\u003e    67490.0,\u003cbr\u003e    0.81171875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 85,\u003cbr\u003e    \"dropout_0\": 0.25184648294881834,\u003cbr\u003e    \"lr\": 0.0011330111150608037\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 27,\u003cbr\u003e  \"values\": [\u003cbr\u003e    72483.0,\u003cbr\u003e    0.6953125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 87,\u003cbr\u003e    \"dropout_0\": 0.46751991666073495,\u003cbr\u003e    \"n_units_l1\": 39,\u003cbr\u003e    \"dropout_1\": 0.45332136687051133,\u003cbr\u003e    \"n_units_l2\": 18,\u003cbr\u003e    \"dropout_2\": 0.42128110302694816,\u003cbr\u003e    \"lr\": 0.005024764149835389\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 28,\u003cbr\u003e  \"values\": [\u003cbr\u003e    44272.0,\u003cbr\u003e    0.809375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 48,\u003cbr\u003e    \"dropout_0\": 0.3730290853339852,\u003cbr\u003e    \"n_units_l1\": 70,\u003cbr\u003e    \"dropout_1\": 0.2205166623940213,\u003cbr\u003e    \"n_units_l2\": 41,\u003cbr\u003e    \"dropout_2\": 0.20713089178299368,\u003cbr\u003e    \"lr\": 0.004319240489850319\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 29,\u003cbr\u003e  \"values\": [\u003cbr\u003e    114522.0,\u003cbr\u003e    0.56328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 113,\u003cbr\u003e    \"dropout_0\": 0.2015368384455394,\u003cbr\u003e    \"n_units_l1\": 122,\u003cbr\u003e    \"dropout_1\": 0.49243507087264715,\u003cbr\u003e    \"n_units_l2\": 92,\u003cbr\u003e    \"dropout_2\": 0.28324533081442227,\u003cbr\u003e    \"lr\": 4.871740326511599e-05\u003cbr\u003e  }\u003cbr\u003e}"],"x":[37632.0,48356.0,87893.0,63882.0,69872.0,90644.0,75960.0,24632.0,22750.0,36627.0,33267.0,96868.0,76013.0,69078.0,71208.0,99100.0,21464.0,78379.0,65108.0,44464.0,61778.0,72254.0,67490.0,72483.0,44272.0,114522.0],"y":[0.2203125,0.81015625,0.75234375,0.22734375,0.834375,0.509375,0.79765625,0.60859375,0.6109375,0.80234375,0.68984375,0.68125,0.81796875,0.82421875,0.346875,0.271875,0.390625,0.1953125,0.79140625,0.64921875,0.8109375,0.63046875,0.81171875,0.6953125,0.809375,0.56328125],"type":"scatter"},{"hovertemplate":"%{text}\u003cextra\u003eBest Trial\u003c\u002fextra\u003e","marker":{"color":[1,9,14,23],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 1,\u003cbr\u003e  \"values\": [\u003cbr\u003e    68284.0,\u003cbr\u003e    0.84296875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 86,\u003cbr\u003e    \"dropout_0\": 0.36894567450802196,\u003cbr\u003e    \"lr\": 0.004780216195952634\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 9,\u003cbr\u003e  \"values\": [\u003cbr\u003e    39700.0,\u003cbr\u003e    0.82890625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 50,\u003cbr\u003e    \"dropout_0\": 0.20334109884465723,\u003cbr\u003e    \"lr\": 0.005362135204023581\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 14,\u003cbr\u003e  \"values\": [\u003cbr\u003e    19850.0,\u003cbr\u003e    0.81328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 25,\u003cbr\u003e    \"dropout_0\": 0.3275131696068301,\u003cbr\u003e    \"lr\": 0.008556436945628066\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 23,\u003cbr\u003e  \"values\": [\u003cbr\u003e    8960.0,\u003cbr\u003e    0.28359375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 10,\u003cbr\u003e    \"dropout_0\": 0.3355658454601602,\u003cbr\u003e    \"n_units_l1\": 56,\u003cbr\u003e    \"dropout_1\": 0.20316352497471232,\u003cbr\u003e    \"lr\": 3.768869802675084e-05\u003cbr\u003e  }\u003cbr\u003e}"],"x":[68284.0,39700.0,19850.0,8960.0],"y":[0.84296875,0.82890625,0.81328125,0.28359375],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
</div>
<br />
<br /><p>Fetch the list of trials on the Pareto front with <a class="reference internal" href="../../reference/generated/optuna.study.Study.html#optuna.study.Study.best_trials" title="optuna.study.Study.best_trials"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_trials</span></code></a>.</p>
<p>For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of trials on the Pareto front: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">trial_with_highest_accuracy</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trial with highest accuracy: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">number: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">params: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">values: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Number of trials on the Pareto front: 4
Trial with highest accuracy:
        number: 1
        params: {&#39;n_layers&#39;: 1, &#39;n_units_l0&#39;: 86, &#39;dropout_0&#39;: 0.36894567450802196, &#39;lr&#39;: 0.004780216195952634}
        values: [68284.0, 0.84296875]
</pre></div>
</div>
<p>Learn which hyperparameters are affecting the flops most with hyperparameter importance.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_param_importances</span><span class="p">(</span>
    <span class="n">study</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target_name</span><span class="o">=</span><span class="s2">&quot;flops&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.0.min.js"></script>                <div id="31485c88-56e0-4045-84c1-f48fed3b191d" class="plotly-graph-div" style="height:100%; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("31485c88-56e0-4045-84c1-f48fed3b191d")) {                    Plotly.newPlot(                        "31485c88-56e0-4045-84c1-f48fed3b191d",                        [{"cliponaxis":false,"hovertemplate":["n_layers (IntDistribution): 0.00048679062816412057\u003cextra\u003e\u003c\u002fextra\u003e","lr (FloatDistribution): 0.0008253842207297845\u003cextra\u003e\u003c\u002fextra\u003e","dropout_0 (FloatDistribution): 0.0034609509265083106\u003cextra\u003e\u003c\u002fextra\u003e","n_units_l0 (IntDistribution): 0.9952268742245978\u003cextra\u003e\u003c\u002fextra\u003e"],"name":"flops","orientation":"h","text":["\u003c0.01","\u003c0.01","\u003c0.01","1.00"],"textposition":"outside","x":[0.00048679062816412057,0.0008253842207297845,0.0034609509265083106,0.9952268742245978],"y":["n_layers","lr","dropout_0","n_units_l0"],"type":"bar"}],                        {"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Hyperparameter Importance"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
</div>
<br />
<br /><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (2 minutes 6.922 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorial-20-recipes-002-multi-objective-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a4ea522762978cb29312e091bc523c7a/002_multi_objective.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">002_multi_objective.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/82aa5c7e2a8d8749f9f6f65a6172eb9f/002_multi_objective.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">002_multi_objective.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4bf0db05e53701be6edd2d2db48ab6db/002_multi_objective.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">002_multi_objective.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Optuna Contributors.
      <span class="commit">Revision <code>ef16a045</code>.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
    <a href="../../privacy.html">Privacy Policy</a>.
     


</footer>
        </div>
      </div>
    </section>
  </div>
  

  
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>